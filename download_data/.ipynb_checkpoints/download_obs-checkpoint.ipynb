{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d7c488-2702-4efb-83d6-474cdecfdd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MAX_ATTEMPTS = 6\n",
    "MIN_VALID_MINS = 5 * 60\n",
    "INCH_2_MM = 25.4\n",
    "MAX_1_MIN = 38\n",
    "MAX_6_HOUR = 840\n",
    "OBS_DATA_PATH = \"/g/data/wa46/user/nl5316/tw_spatial/obs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa84be8d-dcec-44aa-84da-99ef5dac142e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_data(uri):\n",
    "    \"\"\"Fetch the data from the IEM\n",
    "\n",
    "    The IEM download service has some protections in place to keep the number\n",
    "    of inbound requests in check.  This function implements an exponential\n",
    "    backoff to keep individual downloads from erroring.\n",
    "\n",
    "    Args:\n",
    "      uri (string): URL to fetch\n",
    "\n",
    "    Returns:\n",
    "      string data\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < MAX_ATTEMPTS:\n",
    "        try:\n",
    "            data = urlopen(uri, timeout=300).read().decode(\"utf-8\")\n",
    "            if data is not None and not data.startswith(\"ERROR\"):\n",
    "                return data\n",
    "        except Exception as exp:\n",
    "            print(f\"download_data({uri}) failed with {exp}\")\n",
    "            time.sleep(5)\n",
    "        attempt += 1\n",
    "\n",
    "    print(\"Exhausted attempts to download, returning empty data\")\n",
    "\n",
    "\n",
    "states = (\n",
    "    \"AK AL AR AZ CA CO CT DE FL GA HI IA ID IL IN KS KY LA MA MD ME MI MN \"\n",
    "    \"MO MS MT NC ND NE NH NJ NM NV NY OH OK OR PA RI SC SD TN TX UT VA VT \"\n",
    "    \"WA WI WV WY\"\n",
    ")\n",
    "networks = [f\"{state}_ASOS\" for state in states.split()]\n",
    "stations = []\n",
    "for network in networks:\n",
    "    # Get metadata\n",
    "    uri = \"https://mesonet.agron.iastate.edu/\" f\"geojson/network/{network}.geojson\"\n",
    "    data = urlopen(uri)\n",
    "    jdict = json.load(data)\n",
    "    for site in jdict[\"features\"]:\n",
    "        stations.append(site[\"properties\"][\"sid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3d5fc7-1052-44cd-ab44-44595b35dadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_year = 2022\n",
    "end_year = 2024\n",
    "start_month = 1\n",
    "end_month = 9\n",
    "start_day = 1\n",
    "end_day = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d03c22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RBG', 'HUF', 'MTP', 'PAWI', 'JXN', 'JAX', 'GAG', 'RDD', 'EWB', 'AKO', 'RNO', 'GLR', 'SBP', 'PAOT', 'VPZ', 'CAE', 'HGR', 'GED', 'LPR', 'RVS', 'PASI', 'WMC', 'VLD', 'LWT', '1V4', 'HDO', 'AZO', 'ART', 'RFD', 'GEY', 'ELZ', 'MGY', 'UAO', 'BFM', 'WAL', 'MPV', 'HEI', 'RNM', 'HUL', 'ABQ', 'FCM', 'BGD', 'BED', 'HLN', 'FSD', 'RMG', 'SJC', 'XWA', 'BIL', 'ABI', 'TTN', 'COU', 'LAN', 'DYL', 'HRL', 'AGS', 'BPK', 'CSV', 'EET', 'IZG', 'NBC', 'PAKN', 'BOS', 'HSI', 'SWO', 'EEO', 'PHLI', 'OQT', 'UTS', 'LNK', 'NZY', 'FIT', 'MOD', 'HWD', 'IAD', 'BJJ', 'LXT', 'AQV', 'PABR', 'BZN', 'LAS', 'CEC', 'FXE', 'PNE', 'MTO', 'MSY', 'BUY', 'LWM', 'FZY', 'DVN', 'SLN', 'LVK', 'SMO', 'SNY', 'BTL', 'ELP', 'OJC', 'GFL', 'ORE', 'ROC', 'PAKT', 'DRO', 'SSI', 'HRO', 'OSU', 'GTF', 'DEQ', 'DTO', 'SDF', 'MSL', 'DAG', 'MIC', 'LUK', 'IXD', 'DMO', 'MKE', 'P69', 'AUS', 'FTW', 'EST', 'MEM', 'CDS', 'RIC', 'RWF', 'EUF', 'BPT', 'ROW', 'SIY', 'IMT', 'SNT', 'SNS', 'NRS', 'NFL', 'RSL', 'HKS', 'NSE', 'NYC', 'BIS', 'EWR', 'MIA', 'TTD', 'DIK', 'OKB', 'SPS', 'PAIL', 'GLS', 'MLS', 'GEZ', 'MYV', 'MDH', 'TOI', 'MIE', 'ORF', 'PHMK', 'PIT', 'AST', 'HSV', 'TLH', 'BFD', 'SHV', 'FWA', 'LAX', 'PAMR', 'VTA', 'HYR', 'XNA', 'SBN', 'TVR', 'NIP', 'TWF', 'ENW', 'PTK', 'CCR', 'CSM', '12N', 'FLL', 'DSV', 'N60', 'ACK', 'CHA', 'GON', 'ARA', 'CLL', 'CRS', 'MHS', 'FUL', 'NEN', 'BMG', 'GLH', 'ISP', 'BVY', 'RTN', 'TQE', 'JST', 'RBL', 'AFN', 'GPI', 'MYF', 'SDM', 'MBS', 'DXR', 'CDR', 'ASD', 'YNG', 'CAO', 'BOI', 'PHNG', 'EYW', 'FOE', 'LEB', 'LOU', 'OLF', 'CHO', 'SXT', 'HKA', 'TUS', 'EQY', 'BEH', 'PAEN', 'VEL', 'EKO', 'OTM', 'MGM', 'TEB', 'STL', 'DRA', 'PAMC', 'BPI', 'RDM', 'ONO', 'CEZ', 'EAU', 'VGT', 'STP', 'TYS', 'CRG', 'PATA', 'DAN', 'SLK', 'AVX', 'CTB', 'OWD', 'FVE', 'RIW', 'ALK', 'BDL', 'GNR', 'FIG', 'OVS', 'CUB', 'ECG', 'FAR', 'BAF', 'PHJR', 'PEO', 'MDW', 'VRB', 'HVR', 'OSH', 'ALS', 'OFK', 'LIT', 'GKY', 'CQT', 'LIC', 'HOU', 'AVL', 'FTY', 'AAT', 'PDX', 'MLC', 'LWV', 'GGW', 'COS', 'PATK', 'BRL', 'INW', 'SSF', 'ELY', 'GNA', 'HUT', 'PHKO', 'SAT', 'AKQ', 'NQX', 'EED', 'ZZV', 'ITR', 'GMU', 'MVL', 'ADG', 'HIB', 'HTS', 'MMK', 'RUE', 'FYV', 'PAGK', 'CAR', 'MDT', 'BKE', 'SAC', 'JMS', 'TYR', 'DLH', 'PRB', 'SLC', 'DLS', 'MFD', 'CAG', 'PHL', 'CNU', 'HAO', 'BFI', 'CRE', 'PBF', 'RQE', 'DMH', 'IEN', 'CDJ', 'CDC', 'JFK', 'COT', 'P58', 'PDK', 'LND', 'CUT', 'TPH', 'GRB', 'SCK', 'ODO', 'FSM', 'DEC', 'BHM', 'UZA', 'SLE', 'NJK', 'CDW', '8D3', 'GOK', 'CMA', 'BWI', 'GRR', 'ILM', 'SEG', 'DRT', 'BIH', 'TIW', 'AUW', 'PUB', 'SPW', 'PAQT', 'HVN', 'ANB', 'ALB', 'CRQ', 'LXV', 'PKD', 'SYR', 'MSO', 'HBR', 'MKO', 'EWN', 'AGC', 'GPT', 'TPA', 'ATL', 'P92', 'RDU', 'NEW', 'ARR', 'ASE', 'MTH', 'MSS', 'GZH', 'DTW', 'NYG', 'BTV', 'PAYA', 'SJT', 'SFO', 'LMT', 'LLQ', 'VNY', 'LBB', 'GKJ', 'MCI', 'ORH', 'LOL', 'SPG', 'SMF', 'NLC', 'APC', 'INT', 'P28', 'TDZ', 'TUP', 'MWT', 'BGR', 'IOW', 'LBX', 'FNT', 'RAC', 'CXO', 'AAO', 'DCA', 'PANC', 'CXY', 'LVJ', 'JDN', 'NCA', 'STS', 'RAL', 'PHOG', 'LGU', 'JER', 'P60', 'AIA', 'GCK', 'BBW', 'REO', 'PBI', 'GUP', 'TAD', 'UIL', 'D07', 'APN', 'MOT', 'TCC', 'CPR', 'AXN', 'LHX', 'MHE', 'LWD', 'PSC', 'UGN', 'PIE', 'PWA', 'HIO', 'BKB', 'ICR', 'PAJN', 'SJN', 'DFW', 'PAE', 'LNR', 'PYM', 'SEA', 'GFK', 'VSF', 'DAY', 'GEG', 'IAG', 'OMA', 'LLJ', 'NGP', 'HSE', 'NHK', 'OGB', 'FDY', 'BNA', '79J', 'PSX', 'DEW', 'DAW', 'SMQ', 'FFT', 'HON', 'FDR', 'SAD', 'BRO', 'LAF', 'PGD', 'LBT', 'ELM', 'IAH', 'MCK', 'RME', 'SHR', 'EMP', 'DDC', 'LHQ', 'CNO', 'NTD', 'BGM', 'NFJ', 'OXR', 'SPD', 'PADQ', 'MYL', 'PKB', 'WVI', 'LVS', 'GLD', 'RNT', 'CRW', 'CEW', 'ANJ', 'MLI', 'SFF', 'ORD', 'DAL', 'ACT', 'ILG', 'VAY', 'CYS', 'HKY', 'NAK', 'GSH', 'FLD', 'TOL', 'TUL', 'CLM', 'OMK', 'MFI', 'EUG', 'BNO', 'MRH', 'ERI', 'AFW', 'MNN', 'MSP', 'PIA', 'RHI', 'PWM', 'PANN', 'LEE', 'MWL', 'PACV', 'MCB', 'DBQ', 'CKV', 'AMW', 'EVV', 'PQL', 'PHD', 'P68', '1J0', 'CFV', 'MLB', 'TOR', 'PIL', 'BLU', 'PMP', 'HLG', 'DMN', 'RWL', 'AAF', 'TCS', 'AHN', 'AUG', 'ORL', 'ACV', 'LFT', 'VIH', 'PACD', 'IDA', 'SAN', 'NRB', 'FPR', 'DSM', 'ECP', 'BTR', 'GIF', 'BLI', 'SFB', 'GSO', 'MKC', 'LAA', 'MLU', 'APA', 'ISW', 'YKM', 'GWO', 'SBA', 'TOP', 'IPL', 'TVC', 'IPT', 'OXB', 'EKN', 'MKG', 'BYG', 'OKC', 'MPO', 'BIV', 'VUO', 'VCT', 'CPS', 'PRC', 'PBG', 'DWH', 'FWN', 'POU', 'MLF', 'NFE', 'BVO', 'GVL', 'PHP', 'AND', 'MBG', 'MFR', 'CNY', 'PVD', 'MEB', 'RKS', 'CVG', 'TCL', 'BUF', 'ALW', 'TMB', 'GRI', 'LVM', '6R6', 'MFE', 'DUG', 'FFZ', 'PAGY', 'OLM', 'PAHN', 'DAB', 'CLE', 'MIW', 'AMA', 'FOK', 'LWS', 'CEU', 'HWV', 'DET', 'DFI', 'JEF', 'DNL', 'PRN', 'STJ', 'HPN', 'MEH', 'PHTO', 'ATY', 'PATO', 'BUR', 'NUI', 'HYA', 'NKT', 'PIH', 'POF', 'ASX', 'ALO', 'YIP', 'ABE', 'FRG', 'CAK', 'JAN', 'SPI', 'PIR', 'TKI', 'IGM', 'SHN', 'HBG', 'PAH', 'PAVL', 'GSP', 'PASO', 'BKV', 'PABE', 'SAV', 'MTJ', 'P53', 'AKR', 'IJD', 'FMY', 'MGJ', 'QCA', 'TRL', 'AQW', 'MLT', 'SET', 'MVY', 'DPA', 'CON', 'PAOR', 'LGA', 'LAR', 'BFL', 'BHK', 'EVW', 'TVL', 'WST', 'FAY', 'SBM', 'ABY', 'MCN', 'SGR', 'NYL', 'BLF', 'DVT', 'HJO', 'FAT', 'LWC', 'INK', 'LYH', 'PUW', 'PAFA', 'DDH', 'TXK', 'BDR', 'MCO', 'MEI', 'NFW', 'SUS', 'LCH', 'AKH', 'BRD', 'HFD', 'LGB', 'LFK', 'FFC', 'ATT', 'BFF', 'PHX', 'EYE', 'PNC', 'EPH', 'GCN', 'MLP', 'RWI', 'WJF', 'LSE', 'DGW', 'MKL', 'HIE', 'GDP', 'RXE', 'DEN', 'ELN', 'SGF', 'PNS', 'BAZ', 'MOB', 'UKI', 'PASC', 'SUX', 'MHT', 'AOH', 'ICT', 'MCW', 'PGA', 'HLC', 'OPF', 'OVE', 'HOT', 'UUU', 'AMG', 'ONT', 'HRI', 'DKK', 'MAF', 'PHF', 'CID', 'CMX', 'JBR', 'MAI', 'RAP', 'P59', 'CQX', 'SNA', 'RBD', 'LEX', 'BCE', 'CSG', 'IML', 'CKB', 'LOZ', 'ARB', 'MAE', 'LNS', 'FLG', 'DLN', 'BML', 'VCB', 'CNM', 'BWG', 'IRK', 'CRP', 'DCU', 'DHT', 'AVP', 'MHK', 'DTS', 'PWK', 'DHN', 'CMH', 'PTW', 'AOO', 'IWI', 'GJT', 'TAN', 'PAEG', 'MRY', 'AEX', 'FNB', 'AWM', 'ALI', 'MWH', 'OFP', 'CGI', 'MIV', 'DUJ', 'ESF', 'BDE', 'HQM', 'BKL', 'ABR', 'GNV', 'CMI', 'ELD', 'GRD', 'FMN', 'NGU', 'JKL', 'PAKV', 'BMQ', 'OAK', 'SAF', 'PMD', 'ODX', 'UNO', 'SDL', 'STC', 'LAW', 'FST', 'RKP', 'BTM', 'FHR', 'HTL', 'MSN', 'BYI', 'THV', 'IND', 'PAAQ', 'HHR', 'PAKW', 'WLD', 'PAOM', 'SMX', 'GCC', 'PAHO', 'PHNL', 'BKW', 'MCE', 'TRI', 'CQC', 'HZY', 'VTN', 'CNK', 'PSF', 'PABI', 'OLS', 'CLT', 'MGW', 'PLN', 'UIN', 'PDT', 'RDG', 'GUY', 'PABT', 'RST', 'PUC', 'SRQ', 'SBY', 'APF', 'ILN', 'EAT', '2WX', 'WRL']\n"
     ]
    }
   ],
   "source": [
    "file_names = os.listdir(OBS_DATA_PATH)\n",
    "file_names = [name.replace(\".nc\", \"\") for name in file_names]\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3859c826-0b33-4f15-bc10-a50338ce71b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 737171, saw 8\n",
      " for station PALH\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 823172, saw 8\n",
      " for station PAWD\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 879073, saw 8\n",
      " for station BLH\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 6197, saw 8\n",
      " for station NID\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 943761, saw 8\n",
      " for station PSP\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 48066, saw 8\n",
      " for station SDB\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 195960, saw 8\n",
      " for station TRM\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 1018158, saw 8\n",
      " for station RSW\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 979585, saw 8\n",
      " for station HWO\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 446425, saw 8\n",
      " for station PPF\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 814961, saw 8\n",
      " for station DTN\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 1040880, saw 8\n",
      " for station INL\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 256242, saw 8\n",
      " for station JLN\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 1224769, saw 8\n",
      " for station LBF\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 1107340, saw 8\n",
      " for station ACY\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 1054387, saw 8\n",
      " for station MMV\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 1143630, saw 8\n",
      " for station SPB\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 883168, saw 8\n",
      " for station CHS\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 596584, saw 8\n",
      " for station FLO\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 310646, saw 8\n",
      " for station JCT\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 553101, saw 8\n",
      " for station NQI\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 555361, saw 8\n",
      " for station GGG\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 608886, saw 8\n",
      " for station OGD\n",
      "An error occurred: Error tokenizing data. C error: Expected 7 fields in line 180964, saw 8\n",
      " for station ROA\n"
     ]
    }
   ],
   "source": [
    "for station in stations:\n",
    "    if station in file_names:\n",
    "        continue\n",
    "    uri = f\"https://mesonet.agron.iastate.edu/cgi-bin/request/asos1min.py?station={station}&tz=UTC&year1={start_year}&month1={start_month}&day1={start_day}&hour1=0&minute1=0&year2={end_year}&month2={end_month}&day2={end_day}&hour2=23&minute2=59&vars=ptype&vars=precip&sample=1min&what=view&delim=comma&gis=yes\"\n",
    "    try:\n",
    "        data = download_data(uri)\n",
    "    except:\n",
    "        # print(f\"No data for {station}\")\n",
    "        continue\n",
    "    try:\n",
    "        df = pd.read_csv(io.StringIO(data))\n",
    "    except Exception as exp:\n",
    "        print(f\"An error occurred: {exp} for station {station}\")\n",
    "        continue\n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "    df[\"precip\"] = df[\"precip\"].replace(\"M\", np.nan)\n",
    "    df[\"precip\"] = df[\"precip\"].astype(float)\n",
    "    df[\"precip\"] = df[\"precip\"] * INCH_2_MM\n",
    "    df[\"valid(UTC)\"] = pd.to_datetime(df[\"valid(UTC)\"])\n",
    "    df.set_index(\"valid(UTC)\", inplace=True)\n",
    "\n",
    "    df.loc[df[\"precip\"] >= MAX_1_MIN, \"precip\"] = np.nan\n",
    "\n",
    "    precip_df = df[\"precip\"]\n",
    "    df_resampled = precip_df.resample(\"6h\", label=\"right\", closed=\"right\").agg(pd.Series.sum, min_count=MIN_VALID_MINS)\n",
    "    df_resampled = df_resampled\n",
    "    df_resampled.loc[df_resampled >= MAX_6_HOUR] = np.nan\n",
    "\n",
    "    df_resampled.attrs = {\n",
    "        \"station\": df.iloc[0][\"station\"],\n",
    "        \"lat\": df.iloc[0][\"lat\"],\n",
    "        \"lon\": df.iloc[0][\"lon\"],\n",
    "    }\n",
    "    da = df_resampled.to_xarray()\n",
    "    da.attrs = {\n",
    "        \"station\": df.iloc[0][\"station\"],\n",
    "        \"lat\": df.iloc[0][\"lat\"],\n",
    "        \"lon\": df.iloc[0][\"lon\"],\n",
    "    }\n",
    "    da.to_netcdf(f\"{OBS_DATA_PATH}/{station}.nc\")\n",
    "    print(f\"got data for {station}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aeefe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jenv]",
   "language": "python",
   "name": "conda-env-jenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
